"""
train_age_gender_utk_regression_resnet.py

Age as REGRESSION + gender as classification (UTKFace).

Metrics for VKR:
- Age MAE (years): main regression metric
- Age Bin Accuracy: accuracy over bins [0-12, 13-25, 26-40, 41-60, 61+]
- Acc@5 / Acc@10: share of predictions within +/- K years (optional but useful)

Designed to work with:
- data/utkface_mediapipe_cropped  (recommended, generated by prepare_utk_mediapipe_crops.py)
- or original data/utkface_aligned_cropped

Saves weights to: models/age_gender_regression_resnet18.pth
"""

import argparse
import glob
import os
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple

import numpy as np
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from tqdm import tqdm

# --- Age bins (same as in your service/UI) ---
AGE_BINS = [(0, 12), (13, 25), (26, 40), (41, 60), (61, 120)]

def age_to_bin_idx(age_years: float) -> int:
    a = max(0.0, min(float(age_years), 120.0))
    for i, (lo, hi) in enumerate(AGE_BINS):
        if lo <= a <= hi:
            return i
    return len(AGE_BINS) - 1

# UTKFace: [age]_[gender]_[race]_[date&time].jpg  gender: 0=male, 1=female
def parse_utk_filename(path: str) -> Tuple[int, int]:
    name = os.path.basename(path)
    parts = name.split("_")
    age = int(parts[0])
    gender = int(parts[1])
    return age, gender


@dataclass
class Sample:
    path: str
    age: int
    gender: int


class UtkDataset(Dataset):
    def __init__(self, samples: List[Sample], transform=None, max_age: float = 120.0):
        self.samples = samples
        self.transform = transform
        self.max_age = max_age

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        s = self.samples[idx]
        try:
            img = Image.open(s.path).convert("RGB")
        except Exception:
            # If an image is corrupted, fallback to a black image (keeps training running)
            img = Image.new("RGB", (224, 224), (0, 0, 0))

        if self.transform:
            img = self.transform(img)

        # Normalize age to 0..1
        age_norm = float(s.age) / float(self.max_age)
        age_norm = max(0.0, min(1.0, age_norm))
        return img, torch.tensor(age_norm, dtype=torch.float32), torch.tensor(s.gender, dtype=torch.long)


class AgeGenderRegResNet(nn.Module):
    def __init__(self):
        super().__init__()
        backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        in_features = backbone.fc.in_features
        backbone.fc = nn.Identity()
        self.backbone = backbone
        self.head_age = nn.Linear(in_features, 1)
        self.head_gender = nn.Linear(in_features, 2)

    def forward(self, x):
        feats = self.backbone(x)
        age = self.head_age(feats).squeeze(1)          # [B]
        gender_logits = self.head_gender(feats)        # [B,2]
        return age, gender_logits


def compute_class_weights(labels: List[int], num_classes: int) -> torch.Tensor:
    counts = np.bincount(np.array(labels, dtype=np.int64), minlength=num_classes).astype(np.float32)
    total = float(counts.sum())
    weights = total / (num_classes * np.clip(counts, 1.0, None))
    return torch.tensor(weights, dtype=torch.float32)


def make_transforms():
    train_tf = transforms.Compose([
        transforms.Resize(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.RandomResizedCrop(224, scale=(0.80, 1.0)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    val_tf = transforms.Compose([
        transforms.Resize(224),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return train_tf, val_tf


def load_samples(data_root: Path) -> List[Sample]:
    paths = glob.glob(str(data_root / "**/*.jpg"), recursive=True)
    samples: List[Sample] = []
    for p in paths:
        try:
            age, gender = parse_utk_filename(p)
        except Exception:
            continue
        if gender not in (0, 1):
            continue
        if age < 0 or age > 120:
            continue
        samples.append(Sample(path=p, age=age, gender=gender))
    return samples


def _bin_acc_from_tensors(pred_age_years: torch.Tensor, true_age_years: torch.Tensor) -> int:
    # Compute number of correct bins (int), both tensors are 1D on device
    pred_list = pred_age_years.detach().cpu().tolist()
    true_list = true_age_years.detach().cpu().tolist()
    pred_bins = [age_to_bin_idx(v) for v in pred_list]
    true_bins = [age_to_bin_idx(v) for v in true_list]
    correct = sum(1 for p, t in zip(pred_bins, true_bins) if p == t)
    return int(correct)


@torch.no_grad()
def eval_epoch(model, loader, loss_age, loss_gender, device, max_age: float):
    model.eval()
    total = 0
    lsum = 0.0

    mae_sum = 0.0
    g_correct = 0

    bin_correct = 0
    acc5_correct = 0
    acc10_correct = 0

    for x, age_norm, gender in tqdm(loader, desc="Val", leave=False):
        x = x.to(device)
        age_norm = age_norm.to(device)
        gender = gender.to(device)

        pred_age_norm, pred_gender_logits = model(x)

        la = loss_age(pred_age_norm, age_norm)
        lg = loss_gender(pred_gender_logits, gender)
        loss = la + lg

        lsum += float(loss.item()) * x.size(0)
        total += x.size(0)

        # MAE in years
        pred_age = (pred_age_norm * max_age).clamp(0.0, max_age)
        true_age = (age_norm * max_age)

        abs_err = torch.abs(pred_age - true_age)
        mae_sum += abs_err.sum().item()

        # Acc@5 / Acc@10
        acc5_correct += int((abs_err <= 5.0).sum().item())
        acc10_correct += int((abs_err <= 10.0).sum().item())

        # Gender acc
        g_pred = pred_gender_logits.argmax(dim=1)
        g_correct += (g_pred == gender).sum().item()

        # Bin accuracy
        bin_correct += _bin_acc_from_tensors(pred_age, true_age)

    val_loss = lsum / total
    val_mae = mae_sum / total
    val_gender_acc = g_correct / total
    val_bin_acc = bin_correct / total
    val_acc5 = acc5_correct / total
    val_acc10 = acc10_correct / total

    return val_loss, val_mae, val_bin_acc, val_acc5, val_acc10, val_gender_acc


def train():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_root", type=str, default="data/utkface_mediapipe_cropped",
                    help="Folder with UTKFace images (recommended: mediapipe-cropped)")
    ap.add_argument("--save_path", type=str, default="models/age_gender_regression_resnet18.pth")
    ap.add_argument("--epochs", type=int, default=50)
    ap.add_argument("--batch", type=int, default=64)
    ap.add_argument("--lr", type=float, default=1e-4)
    ap.add_argument("--weight_decay", type=float, default=1e-4)
    ap.add_argument("--max_age", type=float, default=120.0)
    ap.add_argument("--num_workers", type=int, default=4)
    ap.add_argument("--seed", type=int, default=42)
    args = ap.parse_args()

    # Reproducibility (good for VKR)
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("[INFO] device:", device)
    print("[INFO] data_root:", args.data_root)

    if device == "cuda":
        torch.backends.cudnn.benchmark = True

    data_root = Path(args.data_root)
    save_path = Path(args.save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)

    samples = load_samples(data_root)
    if not samples:
        raise RuntimeError(f"No samples found in {data_root}")

    rng = np.random.default_rng(args.seed)
    rng.shuffle(samples)

    val_size = int(0.2 * len(samples))
    val_samples = samples[:val_size]
    train_samples = samples[val_size:]

    train_tf, val_tf = make_transforms()
    train_ds = UtkDataset(train_samples, transform=train_tf, max_age=args.max_age)
    val_ds = UtkDataset(val_samples, transform=val_tf, max_age=args.max_age)

    pin_memory = (device == "cuda")

    train_loader = DataLoader(
        train_ds,
        batch_size=args.batch,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=pin_memory,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=args.batch,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=pin_memory,
    )

    gender_weights = compute_class_weights([s.gender for s in train_samples], num_classes=2).to(device)

    model = AgeGenderRegResNet().to(device)

    # Regression loss (normalized target 0..1)
    loss_age = nn.SmoothL1Loss(beta=0.02)
    loss_gender = nn.CrossEntropyLoss(weight=gender_weights)

    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)

    best = None

    for epoch in range(1, args.epochs + 1):
        model.train()
        total = 0
        lsum = 0.0

        for x, age_norm, gender in tqdm(train_loader, desc=f"Train {epoch}/{args.epochs}", leave=False):
            x = x.to(device)
            age_norm = age_norm.to(device)
            gender = gender.to(device)

            opt.zero_grad(set_to_none=True)

            pred_age_norm, pred_gender_logits = model(x)

            la = loss_age(pred_age_norm, age_norm)
            lg = loss_gender(pred_gender_logits, gender)
            loss = la + lg

            loss.backward()
            opt.step()

            lsum += float(loss.item()) * x.size(0)
            total += x.size(0)

        sch.step()
        train_loss = lsum / total

        val_loss, val_mae, val_bin_acc, val_acc5, val_acc10, val_gender_acc = eval_epoch(
            model, val_loader, loss_age, loss_gender, device, args.max_age
        )

        print(
            f"Epoch {epoch}/{args.epochs} | "
            f"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | "
            f"val_mae_years={val_mae:.2f} | val_age_bin_acc={val_bin_acc:.4f} | "
            f"val_acc@5={val_acc5:.4f} | val_acc@10={val_acc10:.4f} | "
            f"val_gender_acc={val_gender_acc:.4f}"
        )

        # Best selection for VKR:
        # 1) minimize MAE
        # 2) maximize bin accuracy
        # 3) maximize gender accuracy
        score = (val_mae, -val_bin_acc, -val_gender_acc)
        if best is None or score < best[0]:
            best = (score, epoch, val_mae, val_bin_acc, val_gender_acc, val_acc5, val_acc10)
            torch.save(model.state_dict(), save_path)
            print(f"[INFO] saved best -> {save_path}")

    print("\nBest:", best)


if __name__ == "__main__":
    train()
